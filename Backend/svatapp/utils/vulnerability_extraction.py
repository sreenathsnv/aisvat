import re
import json
from typing import List, Dict, Any
import fitz
from PIL import Image
import pytesseract
from langchain_community.llms import Ollama
from langchain.schema import Document as LangChainDocument
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import tempfile
import os

def extract_text_from_image(image_path: str) -> str:
    try:
        img = Image.open(image_path)
        text = pytesseract.image_to_string(img)
        return text
    except Exception as e:
        return ""

def extract_text_from_pdf(pdf_path: str) -> tuple[str, list[str]]:
    try:
        doc = fitz.open(pdf_path)
        text = ""
        image_texts = []
        for page in doc:
            text += page.get_text("text") + "\n"
            image_list = page.get_images(full=True)
            for img_index, img in enumerate(image_list):
                xref = img[0]
                base_image = doc.extract_image(xref)
                image_bytes = base_image["image"]
                temp_image_path = os.path.join(tempfile.gettempdir(), f"temp_image_{img_index}.png")
                with open(temp_image_path, "wb") as f:
                    f.write(image_bytes)
                image_text = extract_text_from_image(temp_image_path)
                if image_text.strip():
                    image_texts.append(image_text)
                try:
                    os.remove(temp_image_path)
                except:
                    pass
        return text, image_texts
    except Exception as e:
        return "", []

def extract_structured_vulnerabilities(text: str, llm: Ollama, model_name: str = None) -> List[Dict[str, Any]]:
    prompt_template = PromptTemplate(
        template="""You are an expert in security vulnerability analysis. Your task is to extract structured vulnerability information from the provided text. For each vulnerability mentioned, identify and extract the following fields:
- vulnerability_name: The name or title of the vulnerability
- cve_id: The CVE identifier (e.g., CVE-2023-1234) or "N/A" if not present
- cwe_id: The CWE identifier (e.g., CWE-79) or "N/A" if not present
- description: A brief description of the vulnerability
- type: The type of vulnerability (e.g., Injection, Authentication Flaw) or "Unknown" if not specified
- severity: The severity level (e.g., High, Medium, Low, Critical) or "Medium" if not specified
- risk: The associated risk (e.g., Credential Theft, Admin Access) or "Unknown" if not specified
- recommended_fix: The recommended fix or mitigation steps or "N/A" if not present
- cve_url: The URL for the CVE entry (e.g., https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-1234) or "N/A" if not present
- cwe_url: The URL for the CWE entry (e.g., https://cwe.mitre.org/data/definitions/79.html) or "N/A" if not present
Return the result as a JSON array of objects, where each object contains the above fields. Ensure the JSON is valid and properly formatted. If no vulnerabilities are found, return an empty array.
Text:
{context}
Output:
```json
[]
```""",
        input_variables=["context"]
    )
    try:
        prompt = prompt_template.format(context=text)
        response = llm.invoke(prompt, num_ctx=4096, num_predict=2048)
        json_patterns = [
            r'```(?:json)?\s*\n([\s\S]*?)\n\s*```',
            r'`{3,}(?:json)?\s*\n([\s\S]*?)\n\s*`{3,}',
            r'\[\s*\{[\s\S]*\}\s*\]',
        ]
        json_str = None
        for pattern in json_patterns:
            match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)
            if match:
                if pattern == r'\[\s*\{[\s\S]*\}\s*\]':
                    json_str = match.group(0)
                else:
                    json_str = match.group(1).strip()
                break
        if not json_str:
            return []
        try:
            vulnerabilities = json.loads(json_str)
        except json.JSONDecodeError as e:
            json_str = json_str.replace(",\n}", "\n}")
            json_str = json_str.replace(",\n]", "\n]")
            json_str = json_str.replace("'", '"')
            json_str = re.sub(r':\s*([^"{}\[\],\s][^{}\[\],\s]*)\s*([,}])', r': "\1"\2', json_str)
            if not json_str.endswith("]"):
                json_str += "]"
            if not json_str.startswith("["):
                json_str = "[" + json_str
            try:
                vulnerabilities = json.loads(json_str)
            except json.JSONDecodeError:
                return []
        if not isinstance(vulnerabilities, list):
            return []
        cleaned_vulnerabilities = []
        required_fields = [
            "vulnerability_name", "cve_id", "cwe_id", "description",
            "type", "severity", "risk", "recommended_fix", "cve_url", "cwe_url"
        ]
        for vuln in vulnerabilities:
            if not isinstance(vuln, dict):
                continue
            cleaned_vuln = {}
            for field in required_fields:
                cleaned_vuln[field] = vuln.get(field, "N/A")
            if not cleaned_vuln["cve_id"].startswith("CVE-") and cleaned_vuln["cve_id"] != "N/A":
                cleaned_vuln["cve_id"] = "N/A"
                cleaned_vuln["cve_url"] = "N/A"
            if not cleaned_vuln["cwe_id"].startswith("CWE-") and cleaned_vuln["cwe_id"] != "N/A":
                cleaned_vuln["cwe_id"] = "N/A"
                cleaned_vuln["cwe_url"] = "N/A"
            if cleaned_vuln["severity"] not in ["Critical", "High", "Medium", "Low", "Informational"]:
                cleaned_vuln["severity"] = "Medium"
            if cleaned_vuln["cve_id"] != "N/A" and cleaned_vuln["cve_url"] == "N/A":
                cleaned_vuln["cve_url"] = f"https://cve.mitre.org/cgi-bin/cvename.cgi?name={cleaned_vuln['cve_id']}"
            if cleaned_vuln["cwe_id"] != "N/A" and cleaned_vuln["cwe_url"] == "N/A":
                cwe_number = cleaned_vuln["cwe_id"].replace("CWE-", "")
                cleaned_vuln["cwe_url"] = f"https://cwe.mitre.org/data/definitions/{cwe_number}.html"
            cleaned_vulnerabilities.append(cleaned_vuln)
        return cleaned_vulnerabilities
    except Exception:
        return []

def parse_vulnerability_from_pdf(pdf_path: str, llm: Ollama, model_name: str = None) -> List[Dict[str, Any]]:
    text, image_texts = extract_text_from_pdf(pdf_path)
    all_text = text + "\n" + "\n".join(image_texts)
    return extract_structured_vulnerabilities(all_text, llm, model_name)

def convert_vulnerabilities_to_documents(
    vulnerabilities: List[Dict[str, Any]],
    file_hash: str = None
) -> List[LangChainDocument]:
    docs = []
    for vuln in vulnerabilities:
        content = f"""Vulnerability: {vuln['vulnerability_name']}
CVE ID: {vuln['cve_id']}
CWE ID: {vuln['cwe_id']}
Description: {vuln['description']}
Type: {vuln['type']}
Severity: {vuln['severity']}
Risk: {vuln['risk']}
Recommended Fix: {vuln['recommended_fix']}"""
        metadata = {
            "vulnerability_name": vuln["vulnerability_name"],
            "cve_id": vuln["cve_id"],
            "cwe_id": vuln["cwe_id"],
            "type": vuln["type"],
            "severity": vuln["severity"]
        }
        if file_hash:
            metadata["file_hash"] = file_hash
        docs.append(LangChainDocument(page_content=content, metadata=metadata))
    return docs


def get_qa_chain(vectorstore, llm_temperature=0.7, max_tokens=1024, top_k=3, model_name=None):
    if not vectorstore:
        return None, "Failed to initialize QA chain: No vectorstore provided."
    use_model = model_name or 'llama3.1:8b'
    try:
        llm = Ollama(
            model=use_model,
            temperature=llm_temperature,
            num_ctx=2048,
            num_predict=max_tokens
        )
        retriever = vectorstore.as_retriever(search_kwargs={"k": top_k})
        memory = ConversationBufferMemory(
            memory_key="chat_history",
            output_key="answer",
            return_messages=True
        )
        rag_prompt = PromptTemplate(
            template="""You are an AI security vulnerability expert. Use the following context to answer questions about security vulnerabilities.
            If you don't know the answer, say so clearly.
            CONTEXT:
            {context}
            CHAT HISTORY:
            {chat_history}
            QUESTION:
            {question}
            ANSWER:
            """,
            input_variables=["context", "chat_history", "question"]
        )
        qa_chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=retriever,
            memory=memory,
            combine_docs_chain_kwargs={"prompt": rag_prompt},
            return_source_documents=True,
            verbose=True
        )
        return qa_chain, "QA chain initialized successfully."
    except Exception as e:
        return None, f"Failed to initialize QA chain: {str(e)}"